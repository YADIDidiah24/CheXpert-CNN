{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU9zFz3gOvPG",
        "outputId": "1e31eb0c-a22a-4b8d-92d2-662ebafc4a61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Dataset URL: https://www.kaggle.com/datasets/ashery/chexpert\n",
            "License(s): CC0-1.0\n",
            "chexpert.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "!kaggle datasets download -d ashery/chexpert\n",
        "import zipfile\n",
        "\n",
        "# Assuming 'chexpert.zip' is the name of the downloaded file\n",
        "with zipfile.ZipFile('chexpert.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('CheXpert-v1.0')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install setuptools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TfXtVr6s7Xw6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zqaoMaj47Kr9"
      },
      "outputs": [],
      "source": [
        "objects= pd.read_csv(\"train_visualCheXbert.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "mnpskfGN7aGf",
        "outputId": "62ec06f2-d234-42c9-9709-a3f86046f748"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Frontal/Lateral</th>\n",
              "      <th>AP/PA</th>\n",
              "      <th>Enlarged Cardiomediastinum</th>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <th>Lung Opacity</th>\n",
              "      <th>Lung Lesion</th>\n",
              "      <th>Edema</th>\n",
              "      <th>Consolidation</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Atelectasis</th>\n",
              "      <th>Pneumothorax</th>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <th>Pleural Other</th>\n",
              "      <th>Fracture</th>\n",
              "      <th>Support Devices</th>\n",
              "      <th>No Finding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CheXpert-v1.0/train/patient00001/study1/view1_...</td>\n",
              "      <td>Female</td>\n",
              "      <td>68</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CheXpert-v1.0/train/patient00002/study2/view1_...</td>\n",
              "      <td>Female</td>\n",
              "      <td>87</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CheXpert-v1.0/train/patient00002/study1/view1_...</td>\n",
              "      <td>Female</td>\n",
              "      <td>83</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CheXpert-v1.0/train/patient00002/study1/view2_...</td>\n",
              "      <td>Female</td>\n",
              "      <td>83</td>\n",
              "      <td>Lateral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CheXpert-v1.0/train/patient00003/study1/view1_...</td>\n",
              "      <td>Male</td>\n",
              "      <td>41</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Path     Sex  Age  \\\n",
              "0  CheXpert-v1.0/train/patient00001/study1/view1_...  Female   68   \n",
              "1  CheXpert-v1.0/train/patient00002/study2/view1_...  Female   87   \n",
              "2  CheXpert-v1.0/train/patient00002/study1/view1_...  Female   83   \n",
              "3  CheXpert-v1.0/train/patient00002/study1/view2_...  Female   83   \n",
              "4  CheXpert-v1.0/train/patient00003/study1/view1_...    Male   41   \n",
              "\n",
              "  Frontal/Lateral AP/PA  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
              "0         Frontal    AP                         0.0           0.0   \n",
              "1         Frontal    AP                         1.0           1.0   \n",
              "2         Frontal    AP                         1.0           1.0   \n",
              "3         Lateral   NaN                         1.0           1.0   \n",
              "4         Frontal    AP                         1.0           1.0   \n",
              "\n",
              "   Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
              "0           0.0          0.0    0.0            0.0        0.0          0.0   \n",
              "1           1.0          0.0    1.0            1.0        0.0          1.0   \n",
              "2           1.0          1.0    0.0            1.0        1.0          1.0   \n",
              "3           1.0          1.0    0.0            1.0        1.0          1.0   \n",
              "4           1.0          0.0    1.0            0.0        0.0          0.0   \n",
              "\n",
              "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \\\n",
              "0           0.0               0.0            0.0       0.0              1.0   \n",
              "1           0.0               1.0            0.0       0.0              0.0   \n",
              "2           0.0               0.0            1.0       1.0              0.0   \n",
              "3           0.0               0.0            1.0       1.0              0.0   \n",
              "4           0.0               0.0            0.0       0.0              0.0   \n",
              "\n",
              "   No Finding  \n",
              "0         0.0  \n",
              "1         0.0  \n",
              "2         0.0  \n",
              "3         0.0  \n",
              "4         0.0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "objects.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egBDGn5sXF0T"
      },
      "source": [
        "/content/CheXpert-v1.0/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTvkIqHlUmh3",
        "outputId": "79710e99-8f77-4a63-df03-e3773c32505d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 223414 entries, 0 to 223413\n",
            "Data columns (total 19 columns):\n",
            " #   Column                      Non-Null Count   Dtype  \n",
            "---  ------                      --------------   -----  \n",
            " 0   Path                        223414 non-null  object \n",
            " 1   Sex                         223414 non-null  object \n",
            " 2   Age                         223414 non-null  int64  \n",
            " 3   Frontal/Lateral             223414 non-null  object \n",
            " 4   AP/PA                       191027 non-null  object \n",
            " 5   Enlarged Cardiomediastinum  223414 non-null  float64\n",
            " 6   Cardiomegaly                223414 non-null  float64\n",
            " 7   Lung Opacity                223414 non-null  float64\n",
            " 8   Lung Lesion                 223414 non-null  float64\n",
            " 9   Edema                       223414 non-null  float64\n",
            " 10  Consolidation               223414 non-null  float64\n",
            " 11  Pneumonia                   223414 non-null  float64\n",
            " 12  Atelectasis                 223414 non-null  float64\n",
            " 13  Pneumothorax                223414 non-null  float64\n",
            " 14  Pleural Effusion            223414 non-null  float64\n",
            " 15  Pleural Other               223414 non-null  float64\n",
            " 16  Fracture                    223414 non-null  float64\n",
            " 17  Support Devices             223414 non-null  float64\n",
            " 18  No Finding                  223414 non-null  float64\n",
            "dtypes: float64(14), int64(1), object(4)\n",
            "memory usage: 32.4+ MB\n"
          ]
        }
      ],
      "source": [
        "objects.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wyw6_u-LXol9"
      },
      "outputs": [],
      "source": [
        "path_df = objects[\"Path\"]\n",
        "\n",
        "# Prepend '/content/' to each path in the 'path_df'\n",
        "path_df = path_df.str.replace('^', '/content/', regex=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "dQuPHFpCXqie",
        "outputId": "fef271fa-6df2-4d92-a10c-260731c58dad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    /content/CheXpert-v1.0/train/patient00001/stud...\n",
              "1    /content/CheXpert-v1.0/train/patient00002/stud...\n",
              "2    /content/CheXpert-v1.0/train/patient00002/stud...\n",
              "3    /content/CheXpert-v1.0/train/patient00002/stud...\n",
              "4    /content/CheXpert-v1.0/train/patient00003/stud...\n",
              "Name: Path, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ef0JtP747fDI"
      },
      "outputs": [],
      "source": [
        "# List of label columns\n",
        "LABEL_COLUMNS = [\"Enlarged Cardiomediastinum\", \"Cardiomegaly\", \"Lung Opacity\",\n",
        "                 \"Lung Lesion\", \"Edema\", \"Consolidation\", \"Pneumonia\",\n",
        "                 \"Atelectasis\", \"Pneumothorax\", \"Pleural Effusion\",\n",
        "                 \"Pleural Other\", \"Fracture\", \"Support Devices\", \"No Finding\"]\n",
        "\n",
        "def preprocess_image(img_path, img_size=(224, 224)):\n",
        "    # Load the image from file path, resize, and normalize it\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)  # Decode JPEG image into RGB format\n",
        "    img = tf.image.resize(img, img_size)  # Resize image\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "    return img\n",
        "def load_image_and_labels(row):\n",
        "    # Extract image path and labels\n",
        "    img_path = row['Path']\n",
        "    img = preprocess_image(img_path)\n",
        "\n",
        "    # Extract labels as a tensor\n",
        "    labels = tf.convert_to_tensor(row[LABEL_COLUMNS].values, dtype=tf.float32)\n",
        "\n",
        "    return img, labels  # Return a tuple of (image, labels)\n",
        "\n",
        "def create_dataset(dataframe, batch_size=32):\n",
        "    # Create a TensorFlow Dataset from the dataframe\n",
        "    image_paths = dataframe['Path'].values  # Extract image paths\n",
        "    labels = dataframe[LABEL_COLUMNS].values.astype('float32')  # Convert labels to float32\n",
        "\n",
        "    # Create TensorFlow Dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "\n",
        "    # Map the loading function to the dataset\n",
        "    dataset = dataset.map(lambda img_path, label: (preprocess_image(img_path), label),\n",
        "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Shuffle and batch the dataset\n",
        "    dataset = dataset.shuffle(buffer_size=len(dataframe), reshuffle_each_iteration=True)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)  # Pre-fetch data for better performance\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\yadidiahk\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn)\n",
            "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
            "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
            "     -------------------------------- ----- 51.2/60.8 kB 871.5 kB/s eta 0:00:01\n",
            "     ---------------------------------------- 60.8/60.8 kB 1.1 MB/s eta 0:00:00\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
            "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/11.0 MB 8.3 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 1.1/11.0 MB 14.0 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 1.8/11.0 MB 14.1 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 2.7/11.0 MB 17.1 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 3.1/11.0 MB 16.3 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 3.8/11.0 MB 15.0 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 4.5/11.0 MB 15.3 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 5.3/11.0 MB 15.6 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 6.1/11.0 MB 15.6 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 6.9/11.0 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 7.9/11.0 MB 16.8 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 9.0/11.0 MB 17.4 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.1/11.0 MB 17.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.0/11.0 MB 18.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.0/11.0 MB 17.7 MB/s eta 0:00:00\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
            "   ------------------------------------- -- 286.7/301.8 kB 8.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 301.8/301.8 kB 9.4 MB/s eta 0:00:00\n",
            "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
            "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.9/44.5 MB 18.1 MB/s eta 0:00:03\n",
            "   - -------------------------------------- 1.7/44.5 MB 18.4 MB/s eta 0:00:03\n",
            "   -- ------------------------------------- 2.7/44.5 MB 17.3 MB/s eta 0:00:03\n",
            "   -- ------------------------------------- 3.3/44.5 MB 17.4 MB/s eta 0:00:03\n",
            "   --- ------------------------------------ 4.0/44.5 MB 18.4 MB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 5.0/44.5 MB 18.9 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 5.9/44.5 MB 18.9 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 7.3/44.5 MB 20.4 MB/s eta 0:00:02\n",
            "   ------- -------------------------------- 8.7/44.5 MB 21.5 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 9.0/44.5 MB 19.8 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 10.1/44.5 MB 20.2 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 11.1/44.5 MB 21.1 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 12.6/44.5 MB 22.6 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 14.1/44.5 MB 25.2 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 15.6/44.5 MB 25.1 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 17.1/44.5 MB 27.3 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 18.2/44.5 MB 27.3 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 18.8/44.5 MB 24.2 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 19.7/44.5 MB 26.2 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 20.5/44.5 MB 26.2 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 21.6/44.5 MB 26.2 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 22.7/44.5 MB 25.2 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 24.0/44.5 MB 25.2 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 25.1/44.5 MB 24.2 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 26.3/44.5 MB 24.2 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 27.2/44.5 MB 23.4 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 28.3/44.5 MB 22.6 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 28.7/44.5 MB 22.6 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 29.8/44.5 MB 22.5 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 30.9/44.5 MB 22.6 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 32.2/44.5 MB 23.4 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 33.1/44.5 MB 21.8 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 34.3/44.5 MB 21.8 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 35.5/44.5 MB 22.6 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 36.5/44.5 MB 21.8 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 37.2/44.5 MB 22.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 37.9/44.5 MB 21.9 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 39.1/44.5 MB 22.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 39.8/44.5 MB 22.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 41.2/44.5 MB 23.4 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 41.9/44.5 MB 22.6 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 42.9/44.5 MB 22.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.3/44.5 MB 23.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  44.5/44.5 MB 23.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 44.5/44.5 MB 19.8 MB/s eta 0:00:00\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "N2skdeFrcp3W"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "objects_filtered = objects[LABEL_COLUMNS + ['Path']].copy()\n",
        "\n",
        "# Handle NaN values by filling them with 0 or dropping rows with NaNs\n",
        "objects_filtered.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "train_df, val_df = train_test_split(objects_filtered, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reset index for the new DataFrames\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "val_df.reset_index(drop=True, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AkNc8KYjb1AI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Load a pre-trained model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze the base model layers\n",
        "\n",
        "# Add custom classification layers\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(len(LABEL_COLUMNS), activation='sigmoid')  # Adjust output layer for multi-label classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "decPHolj9iwS"
      },
      "outputs": [],
      "source": [
        "cardiomegaly_data = objects[objects['Cardiomegaly'] == 1.0]\n",
        "pneumonia_data = objects[objects['Pneumonia'] == 1.0]\n",
        "lung_opacity_data = objects[objects['Lung Opacity'] == 1.0]\n",
        "relevant_conditions = objects[\n",
        "    (objects['Cardiomegaly'] == 1.0) |\n",
        "    (objects['Pneumonia'] == 1.0) |\n",
        "    (objects['Lung Opacity'] == 1.0)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "MytLP55DiZuK",
        "outputId": "8e27fa1c-1dc7-4bb9-8d45-bb90080f43dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\yadidiahk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m11,075,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │         \u001b[38;5;34m1,806\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,170,766</span> (42.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,170,766\u001b[0m (42.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,170,766</span> (42.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,170,766\u001b[0m (42.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    # First convolutional layer\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Second convolutional layer\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Third convolutional layer\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Flatten the feature maps\n",
        "    Flatten(),\n",
        "\n",
        "    # Fully connected layer\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Dropout to prevent overfitting\n",
        "\n",
        "    # Output layer for multi-label classification\n",
        "    Dense(len(LABEL_COLUMNS), activation='sigmoid')  # Use 'sigmoid' for multi-label output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-iXfboEiaV0",
        "outputId": "e8fcca95-fd8d-4f22-e068-2f23052af5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node resize/ResizeBilinear defined at (most recent call last):\n<stack traces unavailable>\nError in user-defined function passed to ParallelMapDatasetV2:1 transformation with iterator: Iterator::Root::Prefetch::MemoryCacheImpl::Prefetch::BatchV2::Shuffle::ParallelMapV2: OOM when allocating tensor with shape[1,224,224,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node resize/ResizeBilinear}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_4741]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mcache()\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\yadidiahk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\yadidiahk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node resize/ResizeBilinear defined at (most recent call last):\n<stack traces unavailable>\nError in user-defined function passed to ParallelMapDatasetV2:1 transformation with iterator: Iterator::Root::Prefetch::MemoryCacheImpl::Prefetch::BatchV2::Shuffle::ParallelMapV2: OOM when allocating tensor with shape[1,224,224,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node resize/ResizeBilinear}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_4741]"
          ]
        }
      ],
      "source": [
        "train_dataset = create_dataset(train_df, batch_size=32)\n",
        "val_dataset = create_dataset(val_df, batch_size=32)\n",
        "\n",
        "train_dataset = train_dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=5, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWygtNV5FbPa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
